#  Sentiric LLM Service - Mant覺k ve Ak覺 Mimarisi

**Belge Amac覺:** Bu dok羹man, `llm-service`'in Sentiric platformunun **"soyutlanm覺 beyni"** olarak rol羹n羹 ve dier servislerle olan basit ama kritik etkileimini a癟覺klar.

---

## 1. Stratejik Rol: "Evrensel Dil Terc羹man覺"

Bu servisin tek ve net bir g繹revi vard覺r: Kendisine verilen herhangi bir `prompt`'u, arkada 癟al覺an LLM salay覺c覺s覺n覺n (Gemini, OpenAI vb.) anlayaca覺 formata 癟evirmek, yan覺t覺 almak ve bu yan覺t覺 standart bir metin olarak geri d繹nd羹rmek.

**Bu servis sayesinde platform:**
1.  **Ba覺ms覺z Olur:** Ana orkestrat繹r (`agent-service`), Google'覺n veya OpenAI'覺n SDK'lar覺n覺, API anahtarlar覺n覺 veya veri formatlar覺n覺 bilmek zorunda deildir. Bu karma覺kl覺k tamamen `llm-service` i癟inde saklan覺r.
2.  **Esnek Olur:** Platformun kulland覺覺 "beyni" deitirmek, sadece bu servisin i癟indeki bir adapt繹r羹 veya `.env` dosyas覺n覺 deitirmek kadar kolayd覺r. `agent-service`'te tek sat覺r kod deitirmeye gerek kalmaz.
3.  **襤zole Edilir:** LLM'lerin gerektirdii a覺r Python ba覺ml覺l覺klar覺 (`google-generativeai`, `tensorflow` vb.) platformun geri kalan覺ndan izole edilerek potansiyel 癟ak覺malar 繹nlenir.

---

## 2. Temel al覺ma Prensibi: Basit Bir A Ge癟idi (Gateway)

`llm-service`, kendisine gelen HTTP isteklerini ileyen basit bir a ge癟ididir. Gelen istein i癟indeki `prompt` metnini al覺r ve bunu dorudan, yap覺land覺r覺lm覺 olan LLM salay覺c覺s覺na g繹nderir.

**NEML襤 NOT:** `llm-service`'in kendisi RAG (Retrieval-Augmented Generation) yapmaz. RAG i癟in gerekli olan "bilgi arama" ve "prompt zenginletirme" ilemleri, bu servisi 癟a覺ran **`agent-service`'in sorumluluundad覺r.** `llm-service` sadece kendisine verilen nihai prompt'u iler.

---

## 3. U癟tan Uca 襤stek Ak覺覺

Bir RAG sorgusu s覺ras覺nda `llm-service`'in rol羹 aa覺daki gibidir:

```mermaid
sequenceDiagram
    participant AgentService as Agent Service
    participant KnowledgeService as Knowledge Service
    participant LLMService as LLM Service
    participant GeminiAPI as Google Gemini API

    Note over AgentService: Kullan覺c覺dan gelen soruyla ilgili <br> `KnowledgeService`'ten bilgi (context) al覺nd覺.

    AgentService->>LLMService: POST /generate <br> { prompt: "Context: [...], Soru: [...]" }
    
    Note right of LLMService: Gelen prompt'u al覺r ve Gemini format覺na 癟evirir.

    LLMService->>GeminiAPI: generate_content("Context: [...], Soru: [...]")

    GeminiAPI-->>LLMService: Yan覺t metni
    
    LLMService-->>AgentService: 200 OK <br> { text: "retilen nihai cevap metni..." }
```